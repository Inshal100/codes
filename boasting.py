# -*- coding: utf-8 -*-
"""Boasting.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uno4e4F6ue4puDWrpobSSq-A2w9HutNo
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from matplotlib.colors import ListedColormap
import warnings
warnings.filterwarnings('ignore')

# Load dataset
iris = load_iris()
X = pd.DataFrame(iris.data, columns=iris.feature_names)
y = pd.Series(iris.target, name='target')

# Combine for easier visualization
df = pd.concat([X, y], axis=1)

# Check class distribution
print(df['target'].value_counts())

sns.pairplot(df, hue='target', palette='Set1')
plt.suptitle("Iris Dataset Before Preprocessing", y=1.02)
plt.show()

sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)
for train_idx, test_idx in sss.split(X, y):
    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

# Scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# PCA for 2D visualization
pca = PCA(n_components=2)
X_train_pca = pca.fit_transform(X_train_scaled)
X_test_pca = pca.transform(X_test_scaled)

# Prepare DataFrame for plotting
df_train_pca = pd.DataFrame(X_train_pca, columns=['PC1', 'PC2'])
df_train_pca['target'] = y_train.values

sns.scatterplot(data=df_train_pca, x='PC1', y='PC2', hue='target', palette='Set2')
plt.title("Dataset After Standardization and PCA (Train Set)")
plt.show()

rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train_scaled, y_train)
rf_pred = rf_model.predict(X_test_scaled)

print("Random Forest Accuracy:", accuracy_score(y_test, rf_pred))
print(classification_report(y_test, rf_pred))

# Confusion Matrix (Text)
cm_rf = confusion_matrix(y_test, rf_pred)
print("Confusion Matrix - Random Forest:\n", cm_rf)

# Heatmap
sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', xticklabels=iris.target_names, yticklabels=iris.target_names)
plt.title("Confusion Matrix - Random Forest")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

adb_model = AdaBoostClassifier(n_estimators=100, random_state=42)
adb_model.fit(X_train_scaled, y_train)
adb_pred = adb_model.predict(X_test_scaled)

print("AdaBoost Accuracy:", accuracy_score(y_test, adb_pred))
print(classification_report(y_test, adb_pred))

# Confusion Matrix (Text)
cm_adb = confusion_matrix(y_test, adb_pred)
print("Confusion Matrix - AdaBoost:\n", cm_adb)

# Heatmap
sns.heatmap(cm_adb, annot=True, fmt='d', cmap='Greens', xticklabels=iris.target_names, yticklabels=iris.target_names)
plt.title("Confusion Matrix - AdaBoost")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

def plot_decision_boundary(model, X, y, title):
    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5
    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5
    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),
                         np.arange(y_min, y_max, 0.02))

    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)

    plt.figure(figsize=(8, 6))
    plt.contourf(xx, yy, Z, alpha=0.3, cmap=ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF']))
    sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=y, palette='Set1', edgecolor='k')
    plt.title(title)
    plt.show()

# Train on PCA features for visualization
rf_model_pca = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model_pca.fit(X_train_pca, y_train)

adb_model_pca = AdaBoostClassifier(n_estimators=100, random_state=42)
adb_model_pca.fit(X_train_pca, y_train)

plot_decision_boundary(rf_model_pca, X_train_pca, y_train, "Decision Boundary - Random Forest (PCA Space)")
plot_decision_boundary(adb_model_pca, X_train_pca, y_train, "Decision Boundary - AdaBoost (PCA Space)")

models = ['Random Forest', 'AdaBoost']
accuracies = [accuracy_score(y_test, rf_pred), accuracy_score(y_test, adb_pred)]

sns.barplot(x=models, y=accuracies, palette='pastel')
plt.ylabel('Accuracy')
plt.title('Comparison of Ensemble Models')
plt.ylim(0.8, 1.0)
plt.show()