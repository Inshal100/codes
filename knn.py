# -*- coding: utf-8 -*-
"""KNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qa0YedNNAMNWISh3kTCSkqUcVwexNwYE
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.preprocessing import MinMaxScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.feature_selection import VarianceThreshold, SelectKBest, chi2
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve, ConfusionMatrixDisplay
from sklearn.datasets import load_breast_cancer

data = load_breast_cancer()
df = pd.DataFrame(data.data, columns=data.feature_names)
df['target'] = data.target

plt.figure(figsize=(6, 4))
sns.countplot(x=df['target'], palette=['red', 'green'])
plt.xticks(ticks=[0, 1], labels=['Malignant', 'Benign'])
plt.title("Class Distribution")
plt.xlabel("Class")
plt.ylabel("Count")
plt.show()

plt.figure(figsize=(12, 10))
corr_matrix = df.corr()
sns.heatmap(corr_matrix, cmap='coolwarm', annot=False, linewidths=0.5)
plt.title("Feature Correlation Heatmap")
plt.show()

selected_features = ['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'target']
sns.pairplot(df[selected_features], hue="target", palette=['red', 'green'])
plt.show()

X = df.drop(columns=['target'])
y = df['target']

skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

var_thresh = VarianceThreshold(threshold=0.01)
X_var_selected = var_thresh.fit_transform(X_scaled)

corr_matrix = pd.DataFrame(X_var_selected).corr().abs()

upper_triangle = np.triu(corr_matrix, k=1)
to_drop = [column for column in range(len(corr_matrix)) if any(upper_triangle[:, column] > 0.9)]
X_corr_selected = np.delete(X_var_selected, to_drop, axis=1)

selector = SelectKBest(score_func=chi2, k=10)
X_final = selector.fit_transform(X_corr_selected, y)

# Train kNN Classifier
knn = KNeighborsClassifier(n_neighbors=5)
scores = cross_val_score(knn, X_final, y, cv=skf, scoring='accuracy')

print(f"Cross-Validation Accuracy: {np.mean(scores):.4f}")

X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42, stratify=y)

# Train the KNN model
knn.fit(X_train, y_train)

# Make predictions
y_pred = knn.predict(X_test)
y_proba = knn.predict_proba(X_test)[:, 1]  # Probabilities for ROC-AUC

# Compute Evaluation Metrics
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)
roc_auc = roc_auc_score(y_test, y_proba)

print(f"Accuracy: {accuracy:.4f}")
print("\nClassification Report:\n", classification_rep)
print("\nConfusion Matrix:\n", conf_matrix)
print(f"\nROC-AUC Score: {roc_auc:.4f}")

ConfusionMatrixDisplay.from_predictions(y_test, y_pred)

fpr, tpr, _ = roc_curve(y_test, y_proba)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.4f}')
plt.plot([0, 1], [0, 1], linestyle='--', color='red')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend()
plt.show()

"""# **KNN Regression Model**"""

from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Load regression dataset
X, y = load_diabetes(return_X_y=True)

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize KNN regressor
knn_reg = KNeighborsRegressor(n_neighbors=5)

# Train the model
knn_reg.fit(X_train, y_train)

# Make predictions
y_pred = knn_reg.predict(X_test)

# Evaluate
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse:.2f}")
print(f"RÂ² Score: {r2:.2f}")